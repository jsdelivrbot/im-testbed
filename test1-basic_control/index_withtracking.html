<!DOCTYPE html>
<html>
<body>
  <script src="https://cdn.rawgit.com/mohayonao/web-audio-api-shim/master/build/web-audio-api-shim.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fetch/1.0.0/fetch.min.js"></script>
  <script src="musicforairports_noplay.js"></script>

  <!-- TRACKING CODE BEGINS -->
  <script src="../core/trackingjs/tracking.js-master/build/tracking-min.js"></script>

  <!--TRAINING DATA FOR THE TRACKER-->
  <script src="../core/trackingjs/tracking.js-master/build/data/face-min.js"></script>
  <script src="../core/trackingjs/tracking.js-master/build/data/eye-min.js"></script>
  <script src="../core/trackingjs/tracking.js-master/build/data/mouth-min.js"></script>

  <style>
    video, canvas {
      margin-left: 230px;
      margin-top: 120px;
      position: absolute;
    }

    .rect {
      border: 2px solid #a64ceb;
      left: -1000px;
      position: absolute;
      top: -1000px;
    }
  </style>
</head>
<body>
  <div class="demo-frame">
    <div class="demo-container">
      <video id="video" width="320" height="240" preload autoplay loop muted></video>
      <canvas id="canvas" width="320" height="240"></canvas>
    </div>
  </div>

  <script>
    // initiate music player
    window.onload = function() {
      var video = document.getElementById('video');
      var canvas = document.getElementById('canvas');
      var context = canvas.getContext('2d');

      // Create tracker instance
      var tracker = new tracking.ObjectTracker(['face', 'eye', 'mouth']);
      tracker.setInitialScale(4);
      tracker.setStepSize(2);
      tracker.setEdgesDensity(0.1);

      // Start tracking - this handles all the logic to process pixels
      var trackerTask = tracking.track('#video', tracker, { camera: true });

      // Set tracker to listen for events
      tracker.on('track', function(event) {
        context.clearRect(0, 0, canvas.width, canvas.height);

          if (event.data.length === 0) {
            // No colors were detected in this frame.
          } else {
            event.data.forEach(function(rect) {
              console.log(rect.x, rect.y, rect.height, rect.width);
              context.strokeStyle = '#a64ceb';
              context.strokeRect(rect.x, rect.y, rect.width, rect.height);
              context.font = '11px Helvetica';
              context.fillStyle = "#fff";
              context.fillText('x: ' + rect.x + 'px', rect.x + rect.width + 5, rect.y + 11);
              context.fillText('y: ' + rect.y + 'px', rect.x + rect.width + 5, rect.y + 22);

              // play note
              fetchSample('AirportTerminal.wav').then(convolverBuffer => {
                  // convolution reverb
                  let convolver = audioContext.createConvolver();
                  convolver.buffer = convolverBuffer;
                  convolver.connect(gainNode);
                  gainNode.connect(audioContext.destination);

                  // start different loops at different times, with different lengths
                  // e.g. playSample('Clarinet', 'C2', gainNode, 0);
                  //      startLoop('Grand Piano', 'Eb5',  gainNode, 0.5, 1.0);
                  noterefresh = 2 // seconds

                  playSample('Clarinet', noteName(rect.x),  gainNode, 0)
                });
            });
          }
        });
    

      // Function to draw rectangles, from face_hello_world.html
      window.plot = function(x, y, w, h) {
        var rect = document.createElement('div');
        document.querySelector('.demo-container').appendChild(rect);
        rect.classList.add('rect');
        rect.style.width = w + 'px';
        rect.style.height = h + 'px';
        rect.style.left = (video.offsetLeft + x) + 'px';
        rect.style.top = (video.offsetTop + y) + 'px';
      };
    }


  </script>

  <!-- THIS PLAYS STUFF -->
  <script>
      note = noteName(65);

  </script>

</body>
</html>
